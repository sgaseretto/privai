{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Privacy\n",
    "> Como realizar analisis estadisticos sobre datos sin comprometer la privacidad de los mismos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qué es Differential Privacy\n",
    "Differential Privacy o Privacidad Diferencial busca que podamos realizar analisis estadisticos sobre datos sin violar la privacidad de las personas que puedan existir dentro de ese dataset. Primero tenemos que explicar cuando estamos conservando la privacidad de un usuario.\n",
    "\n",
    "Podemos decir que estamos **preservando la privacidad** de un grupo de personas cuando después de un análisis, el analizador no sabe nada sobre las personas en el dataset, estos permanecen sin ser \"observados\".\n",
    "\n",
    "Cynthia Dwork, pionera en el campo de privacidad diferencial, define ```Differential Privacy``` de de la siguiente manera\n",
    "> Differential Privacy describe una promesa, hecha por el individuo que utilizará los datos, al individuo que provee los datos, y la promesa es:\n",
    ">\n",
    ">\"No se verá afectado, de manera adversa o de otro modo, al permitir que sus datos sean utilizados en cualquier estudio o analysis, sin importar qué otros estudios, conjuntos de datos, o fuentes de información hay disponibles\"\n",
    "\n",
    "## Anonimizar datos no es suficiente\n",
    "Si tenemos un dataset anonimizada, y otro grupo libera un dataset relacionado también anonimizado, muchas veces es posible combinar estos datasets y lograr desanonimizar los datos. Esto fue demostrado con varios ejemplos, como el uso de datasets omo IMDB para desanonimizar usuarios de MovieLens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Privacy en una base de datos de juguete\n",
    "\n",
    "Simulemos que tenemos una base de datos de 5000 usuarios, donde solo tenemos una columna que almacena unos y ceros. Podemos suponer que si esta base de datos fuera una sobre pacientes de cancer, cuando una fila tienen un 1 supongamos que el paciente tiene cancer y 0 cuando no lo tiene.\n",
    "\n",
    "Si removemos una persona de las 5000 podemos estar seguros de que la información de dicho paciente no se filtró. Entonces, es posible realizar una consulta que no cambie sin importar a quien removamos de la base de datos?\n",
    "\n",
    "## Primero creamos la Base de Datos\n",
    "\n",
    "Inicializamos una lizta randomica de 1s y 0s donde cada entrada se corresponde directamente con el numero de personas en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True,  ...,  True,  True, False])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Numero de entradas en DB\n",
    "num_entries = 5000\n",
    "\n",
    "db = torch.rand(num_entries) > 0.5\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar Based de Datos Paralelas\n",
    "\n",
    "Clave para la definicion de ```Differential privacy``` es la habilidad de preguntar \"Cuando consultando una base de datos, si remuevo los datos de una base de datos, será la salida de la consulta diferente?\" Para poder probar esto, debemos construir lo que llamamos \"bases de datos paralelas\", que son bases de datos simples con una entrada removida.\n",
    "\n",
    "En este primer ejemplo, crearemos una lista de todas las bases de datos paralelas a la que actualmente está contenida en la variable ```db```. Luego crearemos una funcion que\"\"\n",
    "- Creará una base de datos inicial\n",
    "- Creará todas las bases de datos paralelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parallel_db(db, remove_index):\n",
    "    return torch.cat((db[0:remove_index], \n",
    "                      db[remove_index+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4999])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_parallel_db(db, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parallel_dbs(db):\n",
    "    parallel_dbs = []\n",
    "    for i in range(len(db)):\n",
    "        pdb = get_parallel_db(db, i)\n",
    "        parallel_dbs.append(pdb)\n",
    "        \n",
    "    return parallel_dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_dbs = get_parallel_dbs(db)\n",
    "len(parallel_dbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parallel_dbs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_and_parallels(num_entries):\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    parallel_dbs = get_parallel_dbs(db)\n",
    "    return (db, parallel_dbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallels(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True, False,  True,  True, False,  True, False])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ True,  True,  True, False,  True,  True, False,  True, False]),\n",
       " tensor([False,  True,  True, False,  True,  True, False,  True, False]),\n",
       " tensor([False,  True,  True, False,  True,  True, False,  True, False]),\n",
       " tensor([False,  True,  True, False,  True,  True, False,  True, False]),\n",
       " tensor([False,  True,  True,  True,  True,  True, False,  True, False]),\n",
       " tensor([False,  True,  True,  True, False,  True, False,  True, False]),\n",
       " tensor([False,  True,  True,  True, False,  True, False,  True, False]),\n",
       " tensor([False,  True,  True,  True, False,  True,  True,  True, False]),\n",
       " tensor([False,  True,  True,  True, False,  True,  True, False, False]),\n",
       " tensor([False,  True,  True,  True, False,  True,  True, False,  True])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midiendo la privacidad de una consulta\n",
    "Queremos ser capaces de consultar nuestra base de datos y evaluar si los resultados de una consulta está filtrando informacion privada. Esto se trata de evaluar si la salida de una consulta cambia cuando removemos a alguien de la base de datos. Específicamente queremos evaluar la máxima cantidad en la que una consulta cambia cuando alguien es removido (maximo sobre todas las posibles personas que pueden ser removidas. Para poder evaluar cuanta \"privacidad se filtra\" o pierde, vamos a iterar sobre cada persona en la base de datos y medir la diferencia entre la salida de la consulta relativa a cuando consultamos la base de datos completa.\n",
    "\n",
    "A modo de ejemplo, acamos que nuestra primera \"consulta\" sea una suma, es decir, vamos a contar la cantidad de 1s que hay en la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallels(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    return db.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_db_result = query(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = 0\n",
    "for pdb in pdbs:\n",
    "    pdb_result = query(pdb)\n",
    "    db_distance = torch.abs(pdb_result - full_db_result)\n",
    "    if (db_distance > sensitivity):\n",
    "        sensitivity = db_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity o L1 Sensitivity\n",
    "Es el valor maximo en el que una consulta cambia cuando removemos un individuo del dataset\n",
    "\n",
    "## Definamos una función para medir la sensibilidad de cualquier funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(query, n_entries=1000):\n",
    "    db, pdbs = create_db_and_parallels(n_entries)\n",
    "    sensitivity = 0\n",
    "    full_db_result = query(db)\n",
    "    for pdb in pdbs:\n",
    "        pdb_result = query(pdb)\n",
    "        db_distance = torch.abs(pdb_result - full_db_result)\n",
    "        if (db_distance > sensitivity):\n",
    "            sensitivity = db_distance\n",
    "    \n",
    "    return sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = sensitivity(query, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos la sensibilidad de la funcion de promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(db):\n",
    "    return db.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(mean, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando la L1 Sensitivity de la función Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_func(db, threshodl=5):\n",
    "    return (db.sum() > threshodl).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(threshold_func, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "0\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sen_f = sensitivity(threshold_func, n_entries=10)\n",
    "    print(sen_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differencing Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, _ = create_db_and_parallels(num_entries=100)\n",
    "pdb = get_parallel_db(db, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_db = query(db)\n",
    "tenth = query(pdb)\n",
    "value = torch.abs(tenth - full_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
